{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e63949b1",
   "metadata": {},
   "source": [
    "# Prueba implementado a nuestros datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab57e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   id                     1000 non-null   object\n",
      " 1   fecha_nacimiento       1000 non-null   object\n",
      " 2   fecha_alta             1000 non-null   object\n",
      " 3   id_municipio           1000 non-null   int64 \n",
      " 4   id_estado              1000 non-null   int64 \n",
      " 5   tipo_persona           1000 non-null   object\n",
      " 6   genero                 1000 non-null   object\n",
      " 7   actividad_empresarial  1000 non-null   object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV \n",
    "clients = pd.read_csv('../data/raw/base_clientes_final.csv')\n",
    "clients.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b1395af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 346011 entries, 0 to 346010\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   id             346011 non-null  object \n",
      " 1   fecha          346011 non-null  object \n",
      " 2   comercio       346011 non-null  object \n",
      " 3   giro_comercio  340423 non-null  object \n",
      " 4   tipo_venta     346011 non-null  object \n",
      " 5   monto          346011 non-null  float64\n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 15.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Cargar el archivo CSV usando la ruta absoluta\n",
    "txn = pd.read_csv('../data/raw/base_transacciones_final.csv')\n",
    "txn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c327cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from fastapi import FastAPI\n",
    "from datetime import datetime\n",
    "\n",
    "# --- 1. LOAD AND PREPROCESS DATA --------------------------------------\n",
    "#txn = pd.read_parquet(\"TransactionData.parquet\")\n",
    "txn[\"fecha\"] = pd.to_datetime(txn[\"fecha\"])\n",
    "txn[\"month\"] = txn[\"fecha\"].dt.to_period(\"M\")\n",
    "\n",
    "agg = (txn.groupby([\"id\", \"month\"])\n",
    "           .agg(spend=(\"monto\", \"sum\"),\n",
    "                n_tx=(\"monto\", \"size\"),\n",
    "                max_tx=(\"monto\", \"max\"),\n",
    "                avg_ticket=(\"monto\", \"mean\"))\n",
    "           .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e09760ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. COMPLETE CALENDAR --------------------------------------------\n",
    "full_idx = pd.MultiIndex.from_product(\n",
    "    [agg[\"id\"].unique(),\n",
    "     pd.period_range(agg[\"month\"].min(), agg[\"month\"].max(), freq=\"M\")],\n",
    "    names=[\"id\", \"month\"]\n",
    ")\n",
    "panel = (agg.set_index([\"id\", \"month\"])\n",
    "             .reindex(full_idx, fill_value=0)\n",
    "             .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dda7b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. STATIC CLIENT DATA -------------------------------------------\n",
    "#clients = pd.read_parquet(\"ClientData.parquet\")\n",
    "today = pd.Timestamp(\"2025-05-24\")\n",
    "clients[\"age\"] = ((today - pd.to_datetime(clients[\"fecha_nacimiento\"])).dt.days // 365)\n",
    "clients[\"tenure_months\"] = ((today - pd.to_datetime(clients[\"fecha_alta\"])).dt.days // 30)\n",
    "\n",
    "static_cols = [\"id\", \"age\", \"tenure_months\", \"id_estado\",\n",
    "               \"tipo_persona\", \"genero\", \"actividad_empresarial\"]\n",
    "panel = panel.merge(clients[static_cols], on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "229e0462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. LAG FEATURES -------------------------------------------------\n",
    "panel = panel.sort_values([\"id\", \"month\"])\n",
    "for k in range(1, 7):\n",
    "    panel[f\"spend_lag{k}\"] = panel.groupby(\"id\")[\"spend\"].shift(k)\n",
    "panel[\"rolling_mean_3\"] = panel.groupby(\"id\")[\"spend\"].rolling(3).mean().reset_index(level=0, drop=True)\n",
    "panel[\"rolling_std_6\"] = panel.groupby(\"id\")[\"spend\"].rolling(6).std().reset_index(level=0, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b26f4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. SEASONALITY + HOLIDAYS --------------------------------------\n",
    "panel[\"month_idx\"] = panel[\"month\"].dt.month\n",
    "panel[\"month_sin\"] = np.sin(2 * np.pi * panel[\"month_idx\"] / 12)\n",
    "panel[\"month_cos\"] = np.cos(2 * np.pi * panel[\"month_idx\"] / 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "213409da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrega fechas importantes en México\n",
    "def is_buen_fin(date): return date.month == 11 and date.day >= 15\n",
    "def is_navidad(date): return date.month == 12 and date.day >= 20\n",
    "def is_mothers_day(date): return date.month == 5 and date.day == 10\n",
    "\n",
    "txn[\"buen_fin\"] = txn[\"fecha\"].apply(is_buen_fin)\n",
    "txn[\"navidad\"] = txn[\"fecha\"].apply(is_navidad)\n",
    "txn[\"dia_madre\"] = txn[\"fecha\"].apply(is_mothers_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6c2db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_agg = txn.groupby([\"id\", txn[\"fecha\"].dt.to_period(\"M\")])[[\"buen_fin\", \"navidad\", \"dia_madre\"]].sum().reset_index()\n",
    "holiday_agg.rename(columns={\"fecha\": \"month\"}, inplace=True)\n",
    "panel = panel.merge(holiday_agg, on=[\"id\", \"month\"], how=\"left\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54cd63d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. TARGET -------------------------------------------------------\n",
    "panel[\"spend_next\"] = panel.groupby(\"id\")[\"spend\"].shift(-1)\n",
    "panel = panel.dropna(subset=[\"spend_next\", \"spend_lag1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f1ea85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. SPLIT --------------------------------------------------------\n",
    "feature_cols = [\n",
    "    \"spend\", \"n_tx\", \"max_tx\", \"avg_ticket\",\n",
    "    \"spend_lag1\", \"spend_lag2\", \"spend_lag3\", \"spend_lag4\", \"spend_lag5\", \"spend_lag6\",\n",
    "    \"rolling_mean_3\", \"rolling_std_6\",\n",
    "    \"age\", \"tenure_months\", \"id_estado\", \"tipo_persona\", \"genero\", \"actividad_empresarial\",\n",
    "    \"month_sin\", \"month_cos\",\n",
    "    \"buen_fin\", \"navidad\", \"dia_madre\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0bf4336",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\"id_estado\", \"tipo_persona\", \"genero\", \"actividad_empresarial\"]\n",
    "for col in cat_features:\n",
    "    panel[col] = panel[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c270734",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = panel[\"month\"] <= panel[\"month\"].max() - 3\n",
    "val_mask = panel[\"month\"] == panel[\"month\"].max() - 2\n",
    "test_mask = panel[\"month\"] == panel[\"month\"].max() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eec69b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>month</th>\n",
       "      <th>spend</th>\n",
       "      <th>n_tx</th>\n",
       "      <th>max_tx</th>\n",
       "      <th>avg_ticket</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure_months</th>\n",
       "      <th>id_estado</th>\n",
       "      <th>tipo_persona</th>\n",
       "      <th>...</th>\n",
       "      <th>spend_lag6</th>\n",
       "      <th>rolling_mean_3</th>\n",
       "      <th>rolling_std_6</th>\n",
       "      <th>month_idx</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>buen_fin</th>\n",
       "      <th>navidad</th>\n",
       "      <th>dia_madre</th>\n",
       "      <th>spend_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003d9abe467a91847d566cf455bd2d7d6c8f7e75</td>\n",
       "      <td>2022-01</td>\n",
       "      <td>585.30</td>\n",
       "      <td>62</td>\n",
       "      <td>54.70</td>\n",
       "      <td>9.440323</td>\n",
       "      <td>27</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>Persona Fisica Sin Actividad Empresarial</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>733.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003d9abe467a91847d566cf455bd2d7d6c8f7e75</td>\n",
       "      <td>2022-02</td>\n",
       "      <td>733.52</td>\n",
       "      <td>62</td>\n",
       "      <td>143.61</td>\n",
       "      <td>11.830968</td>\n",
       "      <td>27</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>Persona Fisica Sin Actividad Empresarial</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>788.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003d9abe467a91847d566cf455bd2d7d6c8f7e75</td>\n",
       "      <td>2022-03</td>\n",
       "      <td>788.37</td>\n",
       "      <td>62</td>\n",
       "      <td>143.61</td>\n",
       "      <td>12.715645</td>\n",
       "      <td>27</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>Persona Fisica Sin Actividad Empresarial</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>702.396667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1329.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003d9abe467a91847d566cf455bd2d7d6c8f7e75</td>\n",
       "      <td>2022-04</td>\n",
       "      <td>1329.37</td>\n",
       "      <td>73</td>\n",
       "      <td>200.48</td>\n",
       "      <td>18.210548</td>\n",
       "      <td>27</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>Persona Fisica Sin Actividad Empresarial</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>950.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1654.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003d9abe467a91847d566cf455bd2d7d6c8f7e75</td>\n",
       "      <td>2022-05</td>\n",
       "      <td>1654.94</td>\n",
       "      <td>90</td>\n",
       "      <td>302.04</td>\n",
       "      <td>18.388222</td>\n",
       "      <td>27</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>Persona Fisica Sin Actividad Empresarial</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1257.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1071.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12994</th>\n",
       "      <td>ff67da037fae796809be0e36fb9cdd0e191c38a4</td>\n",
       "      <td>2022-08</td>\n",
       "      <td>1542.14</td>\n",
       "      <td>12</td>\n",
       "      <td>365.43</td>\n",
       "      <td>128.511667</td>\n",
       "      <td>52</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>Persona Fisica Sin Actividad Empresarial</td>\n",
       "      <td>...</td>\n",
       "      <td>879.53</td>\n",
       "      <td>2052.326667</td>\n",
       "      <td>930.097937</td>\n",
       "      <td>8</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1994.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12995</th>\n",
       "      <td>ff67da037fae796809be0e36fb9cdd0e191c38a4</td>\n",
       "      <td>2022-09</td>\n",
       "      <td>1994.71</td>\n",
       "      <td>13</td>\n",
       "      <td>930.02</td>\n",
       "      <td>153.439231</td>\n",
       "      <td>52</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>Persona Fisica Sin Actividad Empresarial</td>\n",
       "      <td>...</td>\n",
       "      <td>342.24</td>\n",
       "      <td>1918.980000</td>\n",
       "      <td>770.270345</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1310.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12996</th>\n",
       "      <td>ff67da037fae796809be0e36fb9cdd0e191c38a4</td>\n",
       "      <td>2022-10</td>\n",
       "      <td>1310.88</td>\n",
       "      <td>14</td>\n",
       "      <td>729.06</td>\n",
       "      <td>93.634286</td>\n",
       "      <td>52</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>Persona Fisica Sin Actividad Empresarial</td>\n",
       "      <td>...</td>\n",
       "      <td>1890.11</td>\n",
       "      <td>1615.910000</td>\n",
       "      <td>780.514539</td>\n",
       "      <td>10</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1037.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12997</th>\n",
       "      <td>ff67da037fae796809be0e36fb9cdd0e191c38a4</td>\n",
       "      <td>2022-11</td>\n",
       "      <td>1037.00</td>\n",
       "      <td>16</td>\n",
       "      <td>297.79</td>\n",
       "      <td>64.812500</td>\n",
       "      <td>52</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>Persona Fisica Sin Actividad Empresarial</td>\n",
       "      <td>...</td>\n",
       "      <td>262.19</td>\n",
       "      <td>1447.530000</td>\n",
       "      <td>536.837271</td>\n",
       "      <td>11</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2104.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12998</th>\n",
       "      <td>ff67da037fae796809be0e36fb9cdd0e191c38a4</td>\n",
       "      <td>2022-12</td>\n",
       "      <td>2104.34</td>\n",
       "      <td>18</td>\n",
       "      <td>690.78</td>\n",
       "      <td>116.907778</td>\n",
       "      <td>52</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>Persona Fisica Sin Actividad Empresarial</td>\n",
       "      <td>...</td>\n",
       "      <td>2394.75</td>\n",
       "      <td>1484.073333</td>\n",
       "      <td>476.807634</td>\n",
       "      <td>12</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1244.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id    month    spend  n_tx  \\\n",
       "0      003d9abe467a91847d566cf455bd2d7d6c8f7e75  2022-01   585.30    62   \n",
       "1      003d9abe467a91847d566cf455bd2d7d6c8f7e75  2022-02   733.52    62   \n",
       "2      003d9abe467a91847d566cf455bd2d7d6c8f7e75  2022-03   788.37    62   \n",
       "3      003d9abe467a91847d566cf455bd2d7d6c8f7e75  2022-04  1329.37    73   \n",
       "4      003d9abe467a91847d566cf455bd2d7d6c8f7e75  2022-05  1654.94    90   \n",
       "...                                         ...      ...      ...   ...   \n",
       "12994  ff67da037fae796809be0e36fb9cdd0e191c38a4  2022-08  1542.14    12   \n",
       "12995  ff67da037fae796809be0e36fb9cdd0e191c38a4  2022-09  1994.71    13   \n",
       "12996  ff67da037fae796809be0e36fb9cdd0e191c38a4  2022-10  1310.88    14   \n",
       "12997  ff67da037fae796809be0e36fb9cdd0e191c38a4  2022-11  1037.00    16   \n",
       "12998  ff67da037fae796809be0e36fb9cdd0e191c38a4  2022-12  2104.34    18   \n",
       "\n",
       "       max_tx  avg_ticket  age  tenure_months id_estado  \\\n",
       "0       54.70    9.440323   27             66        61   \n",
       "1      143.61   11.830968   27             66        61   \n",
       "2      143.61   12.715645   27             66        61   \n",
       "3      200.48   18.210548   27             66        61   \n",
       "4      302.04   18.388222   27             66        61   \n",
       "...       ...         ...  ...            ...       ...   \n",
       "12994  365.43  128.511667   52             80        60   \n",
       "12995  930.02  153.439231   52             80        60   \n",
       "12996  729.06   93.634286   52             80        60   \n",
       "12997  297.79   64.812500   52             80        60   \n",
       "12998  690.78  116.907778   52             80        60   \n",
       "\n",
       "                                   tipo_persona  ... spend_lag6  \\\n",
       "0      Persona Fisica Sin Actividad Empresarial  ...       0.00   \n",
       "1      Persona Fisica Sin Actividad Empresarial  ...       0.00   \n",
       "2      Persona Fisica Sin Actividad Empresarial  ...       0.00   \n",
       "3      Persona Fisica Sin Actividad Empresarial  ...       0.00   \n",
       "4      Persona Fisica Sin Actividad Empresarial  ...       0.00   \n",
       "...                                         ...  ...        ...   \n",
       "12994  Persona Fisica Sin Actividad Empresarial  ...     879.53   \n",
       "12995  Persona Fisica Sin Actividad Empresarial  ...     342.24   \n",
       "12996  Persona Fisica Sin Actividad Empresarial  ...    1890.11   \n",
       "12997  Persona Fisica Sin Actividad Empresarial  ...     262.19   \n",
       "12998  Persona Fisica Sin Actividad Empresarial  ...    2394.75   \n",
       "\n",
       "      rolling_mean_3  rolling_std_6  month_idx     month_sin     month_cos  \\\n",
       "0           0.000000       0.000000          1  5.000000e-01  8.660254e-01   \n",
       "1           0.000000       0.000000          2  8.660254e-01  5.000000e-01   \n",
       "2         702.396667       0.000000          3  1.000000e+00  6.123234e-17   \n",
       "3         950.420000       0.000000          4  8.660254e-01 -5.000000e-01   \n",
       "4        1257.560000       0.000000          5  5.000000e-01 -8.660254e-01   \n",
       "...              ...            ...        ...           ...           ...   \n",
       "12994    2052.326667     930.097937          8 -8.660254e-01 -5.000000e-01   \n",
       "12995    1918.980000     770.270345          9 -1.000000e+00 -1.836970e-16   \n",
       "12996    1615.910000     780.514539         10 -8.660254e-01  5.000000e-01   \n",
       "12997    1447.530000     536.837271         11 -5.000000e-01  8.660254e-01   \n",
       "12998    1484.073333     476.807634         12 -2.449294e-16  1.000000e+00   \n",
       "\n",
       "       buen_fin  navidad  dia_madre  spend_next  \n",
       "0           0.0      0.0        0.0      733.52  \n",
       "1           0.0      0.0        0.0      788.37  \n",
       "2           0.0      0.0        0.0     1329.37  \n",
       "3           0.0      0.0        0.0     1654.94  \n",
       "4           0.0      0.0        5.0     1071.80  \n",
       "...         ...      ...        ...         ...  \n",
       "12994       0.0      0.0        0.0     1994.71  \n",
       "12995       0.0      0.0        0.0     1310.88  \n",
       "12996       0.0      0.0        0.0     1037.00  \n",
       "12997       7.0      0.0        0.0     2104.34  \n",
       "12998       0.0      5.0        0.0     1244.49  \n",
       "\n",
       "[12000 rows x 27 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf8ac10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = panel.loc[train_mask, feature_cols], panel.loc[train_mask, \"spend_next\"]\n",
    "X_val, y_val = panel.loc[val_mask, feature_cols], panel.loc[val_mask, \"spend_next\"]\n",
    "X_test, y_test = panel.loc[test_mask, feature_cols], panel.loc[test_mask, \"spend_next\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab87d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "from lightgbm import early_stopping\n",
    "\n",
    "\n",
    "# --- 8. HYPERPARAMETER OPTIMIZATION ----------------------------------\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"regression_l1\",\n",
    "        \"n_estimators\": 800,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 128),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 100),\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "    }\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=\"l1\",\n",
    "    categorical_feature=[\"id_estado\", \"tipo_persona\", \"genero\", \"actividad_empresarial\"],\n",
    "    callbacks=[early_stopping(stopping_rounds=50)],\n",
    ")\n",
    "    preds = model.predict(X_val)\n",
    "    return np.mean(np.abs(preds - y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45e8ecdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:26,982] A new study created in memory with name: no-name-e8b308b0-c52b-4e20-94e8-4652a2e49f75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:27,850] Trial 0 finished with value: 537.2234148321185 and parameters: {'num_leaves': 114, 'min_child_samples': 100}. Best is trial 0 with value: 537.2234148321185.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's l1: 537.223\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:28,735] Trial 1 finished with value: 536.5753779860544 and parameters: {'num_leaves': 100, 'min_child_samples': 46}. Best is trial 1 with value: 536.5753779860544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's l1: 536.575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:29,587] Trial 2 finished with value: 540.1268979413113 and parameters: {'num_leaves': 80, 'min_child_samples': 85}. Best is trial 1 with value: 536.5753779860544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's l1: 540.127\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:31,557] Trial 3 finished with value: 532.4420190916958 and parameters: {'num_leaves': 89, 'min_child_samples': 27}. Best is trial 3 with value: 532.4420190916958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[423]\tvalid_0's l1: 532.442\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:33,170] Trial 4 finished with value: 533.7639389851067 and parameters: {'num_leaves': 89, 'min_child_samples': 58}. Best is trial 3 with value: 532.4420190916958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[357]\tvalid_0's l1: 533.764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:33,664] Trial 5 finished with value: 535.3572811668444 and parameters: {'num_leaves': 32, 'min_child_samples': 82}. Best is trial 3 with value: 532.4420190916958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[198]\tvalid_0's l1: 535.357\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:34,543] Trial 6 finished with value: 539.5111788066713 and parameters: {'num_leaves': 72, 'min_child_samples': 75}. Best is trial 3 with value: 532.4420190916958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's l1: 539.511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[515]\tvalid_0's l1: 535.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:36,833] Trial 7 finished with value: 535.6782482626596 and parameters: {'num_leaves': 91, 'min_child_samples': 36}. Best is trial 3 with value: 532.4420190916958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:37,660] Trial 8 finished with value: 528.8747763932231 and parameters: {'num_leaves': 56, 'min_child_samples': 18}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[262]\tvalid_0's l1: 528.875\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:38,674] Trial 9 finished with value: 539.390577599312 and parameters: {'num_leaves': 102, 'min_child_samples': 62}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[199]\tvalid_0's l1: 539.391\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:39,261] Trial 10 finished with value: 532.7348492341072 and parameters: {'num_leaves': 48, 'min_child_samples': 19}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's l1: 532.735\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:40,325] Trial 11 finished with value: 532.901305410106 and parameters: {'num_leaves': 59, 'min_child_samples': 18}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[298]\tvalid_0's l1: 532.901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:40,973] Trial 12 finished with value: 532.5979864325271 and parameters: {'num_leaves': 23, 'min_child_samples': 31}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[340]\tvalid_0's l1: 532.598\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:41,827] Trial 13 finished with value: 531.7997926565831 and parameters: {'num_leaves': 54, 'min_child_samples': 10}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's l1: 531.8\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:42,586] Trial 14 finished with value: 532.8019621205613 and parameters: {'num_leaves': 50, 'min_child_samples': 12}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[228]\tvalid_0's l1: 532.802\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:43,564] Trial 15 finished with value: 535.9672100486175 and parameters: {'num_leaves': 65, 'min_child_samples': 40}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's l1: 535.967\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:44,325] Trial 16 finished with value: 532.8236170959651 and parameters: {'num_leaves': 38, 'min_child_samples': 12}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's l1: 532.824\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:45,730] Trial 17 finished with value: 535.0490833941051 and parameters: {'num_leaves': 52, 'min_child_samples': 48}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's l1: 535.049\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:47,571] Trial 18 finished with value: 531.2620860398835 and parameters: {'num_leaves': 126, 'min_child_samples': 25}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[239]\tvalid_0's l1: 531.262\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:49,439] Trial 19 finished with value: 533.6000917711386 and parameters: {'num_leaves': 118, 'min_child_samples': 22}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[307]\tvalid_0's l1: 533.6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[399]\tvalid_0's l1: 535.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:51,974] Trial 20 finished with value: 535.5891140709217 and parameters: {'num_leaves': 125, 'min_child_samples': 29}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:53,188] Trial 21 finished with value: 530.0744026370642 and parameters: {'num_leaves': 38, 'min_child_samples': 13}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[238]\tvalid_0's l1: 530.074\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[384]\tvalid_0's l1: 530.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:54,456] Trial 22 finished with value: 530.4263078298657 and parameters: {'num_leaves': 40, 'min_child_samples': 23}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:54,950] Trial 23 finished with value: 531.8829887528436 and parameters: {'num_leaves': 20, 'min_child_samples': 38}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's l1: 531.883\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:55,546] Trial 24 finished with value: 532.2766536960356 and parameters: {'num_leaves': 39, 'min_child_samples': 19}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's l1: 532.277\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:56,043] Trial 25 finished with value: 534.8175761976814 and parameters: {'num_leaves': 31, 'min_child_samples': 49}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's l1: 534.818\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:56,690] Trial 26 finished with value: 530.8645801723285 and parameters: {'num_leaves': 44, 'min_child_samples': 31}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's l1: 530.865\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:57,929] Trial 27 finished with value: 535.5902573567524 and parameters: {'num_leaves': 64, 'min_child_samples': 10}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[282]\tvalid_0's l1: 535.59\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:58,687] Trial 28 finished with value: 530.9415894542431 and parameters: {'num_leaves': 28, 'min_child_samples': 18}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's l1: 530.942\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:59,288] Trial 29 finished with value: 534.8054905950992 and parameters: {'num_leaves': 16, 'min_child_samples': 70}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's l1: 534.805\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:12:59,977] Trial 30 finished with value: 533.2606749186734 and parameters: {'num_leaves': 40, 'min_child_samples': 35}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's l1: 533.261\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:13:00,924] Trial 31 finished with value: 533.1634110793759 and parameters: {'num_leaves': 42, 'min_child_samples': 24}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's l1: 533.163\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:13:02,200] Trial 32 finished with value: 531.7773300728567 and parameters: {'num_leaves': 43, 'min_child_samples': 31}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[323]\tvalid_0's l1: 531.777\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:13:03,282] Trial 33 finished with value: 537.2083407205322 and parameters: {'num_leaves': 72, 'min_child_samples': 96}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[228]\tvalid_0's l1: 537.208\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:13:04,602] Trial 34 finished with value: 537.1306650311991 and parameters: {'num_leaves': 57, 'min_child_samples': 43}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's l1: 537.131\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:13:05,366] Trial 35 finished with value: 531.9819787969093 and parameters: {'num_leaves': 35, 'min_child_samples': 15}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[275]\tvalid_0's l1: 531.982\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:13:06,147] Trial 36 finished with value: 530.7459527704068 and parameters: {'num_leaves': 27, 'min_child_samples': 25}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[361]\tvalid_0's l1: 530.746\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:13:06,823] Trial 37 finished with value: 530.9174873548678 and parameters: {'num_leaves': 28, 'min_child_samples': 24}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[271]\tvalid_0's l1: 530.917\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:13:07,510] Trial 38 finished with value: 535.062008549082 and parameters: {'num_leaves': 47, 'min_child_samples': 54}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's l1: 535.062\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3153\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 796.234985\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 15:13:08,656] Trial 39 finished with value: 536.3462085430441 and parameters: {'num_leaves': 78, 'min_child_samples': 16}. Best is trial 8 with value: 528.8747763932231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's l1: 536.346\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=40)\n",
    "best_params = study.best_params\n",
    "best_params.update({\n",
    "    \"objective\": \"regression_l1\",\n",
    "    \"n_estimators\": 800,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136b23bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- 9. FINAL MODEL TRAINING -----------------------------------------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mlgb\u001b[49m.LGBMRegressor(**best_params)\n\u001b[32m      3\u001b[39m model.fit(\n\u001b[32m      4\u001b[39m     X_train, y_train,\n\u001b[32m      5\u001b[39m     eval_set=[(X_val, y_val)],\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     callbacks=[early_stopping(stopping_rounds=\u001b[32m50\u001b[39m)]\n\u001b[32m      9\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'lgb' is not defined"
     ]
    }
   ],
   "source": [
    "# --- 9. FINAL MODEL TRAINING -----------------------------------------\n",
    "model = lgb.LGBMRegressor(**best_params)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=\"l1\",\n",
    "    categorical_feature=[\"id_estado\", \"tipo_persona\", \"genero\", \"actividad_empresarial\"],\n",
    "    callbacks=[early_stopping(stopping_rounds=50)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d6199ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan Marco\\AppData\\Local\\Temp\\ipykernel_10368\\590626810.py:6: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  segment_medians = panel.groupby(\"id_estado\")[\"spend_next\"].median().to_dict()\n"
     ]
    }
   ],
   "source": [
    "# --- 10. SCORING FUNCTIONS -------------------------------------------\n",
    "def predict_client_next_month(model, client_id, monthly_panel):\n",
    "    features = monthly_panel.loc[monthly_panel[\"id\"] == client_id].sort_values(\"month\").tail(1)\n",
    "    return float(model.predict(features[feature_cols]))\n",
    "\n",
    "segment_medians = panel.groupby(\"id_estado\")[\"spend_next\"].median().to_dict()\n",
    "\n",
    "def safe_predict(client_id):\n",
    "    hist_len = panel.loc[panel[\"id\"] == client_id, \"spend\"].count()\n",
    "    if hist_len < 4:\n",
    "        segment = panel.loc[panel[\"id\"] == client_id, \"id_estado\"].iat[0]\n",
    "        return segment_medians.get(segment, 0)\n",
    "    return predict_client_next_month(model, client_id, panel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37d9cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 11. FASTAPI SERVER ----------------------------------------------\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/forecast/{client_id}\")\n",
    "def forecast(client_id: int):\n",
    "    y_hat = safe_predict(client_id)\n",
    "    return {\"client_id\": client_id, \"next_month_spend\": y_hat}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311785c1",
   "metadata": {},
   "source": [
    "# Completo de Facundo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ccf93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   id                     1000 non-null   object\n",
      " 1   fecha_nacimiento       1000 non-null   object\n",
      " 2   fecha_alta             1000 non-null   object\n",
      " 3   id_municipio           1000 non-null   int64 \n",
      " 4   id_estado              1000 non-null   int64 \n",
      " 5   tipo_persona           1000 non-null   object\n",
      " 6   genero                 1000 non-null   object\n",
      " 7   actividad_empresarial  1000 non-null   object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV \n",
    "clients = pd.read_csv('../data/raw/base_clientes_final.csv')\n",
    "clients.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d748c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 346011 entries, 0 to 346010\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   id             346011 non-null  object \n",
      " 1   fecha          346011 non-null  object \n",
      " 2   comercio       346011 non-null  object \n",
      " 3   giro_comercio  340423 non-null  object \n",
      " 4   tipo_venta     346011 non-null  object \n",
      " 5   monto          346011 non-null  float64\n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 15.8+ MB\n"
     ]
    }
   ],
   "source": [
    "txn = pd.read_csv('../data/raw/base_transacciones_final.csv')\n",
    "txn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39cc6c7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: tipo_persona: object, genero: object, actividad_empresarial: object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[32m     93\u001b[39m     panel[col] = panel[col].astype(\u001b[33m\"\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     95\u001b[39m model = lgb.LGBMRegressor(\n\u001b[32m     96\u001b[39m     objective     = \u001b[33m\"\u001b[39m\u001b[33mregression_l1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     97\u001b[39m     n_estimators  = \u001b[32m800\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m     colsample_bytree = \u001b[32m0.8\u001b[39m,\n\u001b[32m    102\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ml1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Corrected early stopping\u001b[39;49;00m\n\u001b[32m    110\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_client_next_month\u001b[39m(model, client_id, monthly_panel):\n\u001b[32m    113\u001b[39m     features = monthly_panel.loc[\n\u001b[32m    114\u001b[39m         monthly_panel[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m] == client_id\n\u001b[32m    115\u001b[39m     ].sort_values(\u001b[33m\"\u001b[39m\u001b[33mmonth\u001b[39m\u001b[33m\"\u001b[39m).tail(\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# most recent month\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Juan Marco\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lightgbm\\sklearn.py:1398\u001b[39m, in \u001b[36mLGBMRegressor.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m   1382\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1383\u001b[39m     X: _LGBM_ScikitMatrixLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1395\u001b[39m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1396\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mLGBMRegressor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1397\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1411\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Juan Marco\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lightgbm\\sklearn.py:1049\u001b[39m, in \u001b[36mLGBMModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1046\u001b[39m evals_result: _EvalResultDict = {}\n\u001b[32m   1047\u001b[39m callbacks.append(record_evaluation(evals_result))\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m._n_features = \u001b[38;5;28mself\u001b[39m._Booster.num_feature()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Juan Marco\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lightgbm\\engine.py:297\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     booster = \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[32m    299\u001b[39m         booster.set_train_data_name(train_data_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Juan Marco\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lightgbm\\basic.py:3656\u001b[39m, in \u001b[36mBooster.__init__\u001b[39m\u001b[34m(self, params, train_set, model_file, model_str)\u001b[39m\n\u001b[32m   3649\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_network(\n\u001b[32m   3650\u001b[39m         machines=machines,\n\u001b[32m   3651\u001b[39m         local_listen_port=params[\u001b[33m\"\u001b[39m\u001b[33mlocal_listen_port\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   3652\u001b[39m         listen_time_out=params.get(\u001b[33m\"\u001b[39m\u001b[33mtime_out\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m120\u001b[39m),\n\u001b[32m   3653\u001b[39m         num_machines=params[\u001b[33m\"\u001b[39m\u001b[33mnum_machines\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   3654\u001b[39m     )\n\u001b[32m   3655\u001b[39m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3656\u001b[39m \u001b[43mtrain_set\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3657\u001b[39m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[32m   3658\u001b[39m params.update(train_set.get_params())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Juan Marco\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lightgbm\\basic.py:2590\u001b[39m, in \u001b[36mDataset.construct\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2585\u001b[39m             \u001b[38;5;28mself\u001b[39m._set_init_score_by_predictor(\n\u001b[32m   2586\u001b[39m                 predictor=\u001b[38;5;28mself\u001b[39m._predictor, data=\u001b[38;5;28mself\u001b[39m.data, used_indices=used_indices\n\u001b[32m   2587\u001b[39m             )\n\u001b[32m   2588\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2589\u001b[39m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2590\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2594\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2595\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2596\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2597\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.free_raw_data:\n\u001b[32m   2604\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Juan Marco\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lightgbm\\basic.py:2123\u001b[39m, in \u001b[36mDataset._lazy_init\u001b[39m\u001b[34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[39m\n\u001b[32m   2121\u001b[39m     categorical_feature = reference.categorical_feature\n\u001b[32m   2122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd_DataFrame):\n\u001b[32m-> \u001b[39m\u001b[32m2123\u001b[39m     data, feature_name, categorical_feature, \u001b[38;5;28mself\u001b[39m.pandas_categorical = \u001b[43m_data_from_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2124\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2127\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpandas_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpandas_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2128\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2129\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m _is_pyarrow_table(data) \u001b[38;5;129;01mand\u001b[39;00m feature_name == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2130\u001b[39m     feature_name = data.column_names\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Juan Marco\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lightgbm\\basic.py:868\u001b[39m, in \u001b[36m_data_from_pandas\u001b[39m\u001b[34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[39m\n\u001b[32m    864\u001b[39m df_dtypes.append(np.float32)\n\u001b[32m    865\u001b[39m target_dtype = np.result_type(*df_dtypes)\n\u001b[32m    867\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m     \u001b[43m_pandas_to_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_dtype\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    869\u001b[39m     feature_name,\n\u001b[32m    870\u001b[39m     categorical_feature,\n\u001b[32m    871\u001b[39m     pandas_categorical,\n\u001b[32m    872\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Juan Marco\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lightgbm\\basic.py:814\u001b[39m, in \u001b[36m_pandas_to_numpy\u001b[39m\u001b[34m(data, target_dtype)\u001b[39m\n\u001b[32m    810\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_pandas_to_numpy\u001b[39m(\n\u001b[32m    811\u001b[39m     data: pd_DataFrame,\n\u001b[32m    812\u001b[39m     target_dtype: \u001b[33m\"\u001b[39m\u001b[33mnp.typing.DTypeLike\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    813\u001b[39m ) -> np.ndarray:\n\u001b[32m--> \u001b[39m\u001b[32m814\u001b[39m     \u001b[43m_check_for_bad_pandas_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    815\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    816\u001b[39m         \u001b[38;5;66;03m# most common case (no nullable dtypes)\u001b[39;00m\n\u001b[32m    817\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m data.to_numpy(dtype=target_dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Juan Marco\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lightgbm\\basic.py:805\u001b[39m, in \u001b[36m_check_for_bad_pandas_dtypes\u001b[39m\u001b[34m(pandas_dtypes_series)\u001b[39m\n\u001b[32m    799\u001b[39m bad_pandas_dtypes = [\n\u001b[32m    800\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpandas_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    801\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m column_name, pandas_dtype \u001b[38;5;129;01min\u001b[39;00m pandas_dtypes_series.items()\n\u001b[32m    802\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_allowed_numpy_dtype(pandas_dtype.type)\n\u001b[32m    803\u001b[39m ]\n\u001b[32m    804\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bad_pandas_dtypes:\n\u001b[32m--> \u001b[39m\u001b[32m805\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    806\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpandas dtypes must be int, float or bool.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFields with bad pandas dtypes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(bad_pandas_dtypes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    807\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: tipo_persona: object, genero: object, actividad_empresarial: object"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1.  TXN → MONTHLY PANEL ----------------------------------------\n",
    "# txn = pd.read_parquet(\"TransactionData.parquet\")\n",
    "txn[\"fecha\"]  = pd.to_datetime(txn[\"fecha\"])\n",
    "txn[\"month\"]  = txn[\"fecha\"].dt.to_period(\"M\")\n",
    "\n",
    "agg = (txn.groupby([\"id\", \"month\"])\n",
    "           .agg(spend      = (\"monto\", \"sum\"),\n",
    "                n_tx       = (\"monto\", \"size\"),\n",
    "                max_tx     = (\"monto\", \"max\"),\n",
    "                avg_ticket = (\"monto\", \"mean\"))\n",
    "           .reset_index())\n",
    "\n",
    "# --- 2.  COMPLETE CALENDAR PER CLIENT -------------------------------\n",
    "full_idx = pd.MultiIndex.from_product(\n",
    "    [agg[\"id\"].unique(),\n",
    "     pd.period_range(agg[\"month\"].min(), agg[\"month\"].max(), freq=\"M\")],\n",
    "    names=[\"id\", \"month\"]\n",
    ")\n",
    "panel = (agg.set_index([\"id\", \"month\"])\n",
    "             .reindex(full_idx, fill_value=0)\n",
    "             .reset_index())\n",
    "\n",
    "# --- 3.  STATIC CLIENT DATA -----------------------------------------\n",
    "# clients = pd.read_parquet(\"ClientData.parquet\")\n",
    "today   = pd.Timestamp(\"2025-05-24\")         # FIXED date for reproducibility\n",
    "clients[\"age\"]           = ((today - pd.to_datetime(clients[\"fecha_nacimiento\"]))\n",
    "                            .dt.days // 365)\n",
    "clients[\"tenure_months\"] = ((today - pd.to_datetime(clients[\"fecha_alta\"]))\n",
    "                            .dt.days // 30)\n",
    "\n",
    "static_cols = [\"id\", \"age\", \"tenure_months\", \"id_estado\",\n",
    "               \"tipo_persona\", \"genero\", \"actividad_empresarial\"]\n",
    "panel = panel.merge(clients[static_cols], on=\"id\", how=\"left\")\n",
    "\n",
    "# --- 4.  LAG FEATURES -----------------------------------------------\n",
    "panel = panel.sort_values([\"id\", \"month\"])\n",
    "for k in range(1, 7):\n",
    "    panel[f\"spend_lag{k}\"] = panel.groupby(\"id\")[\"spend\"].shift(k)\n",
    "panel[\"rolling_mean_3\"] = (panel.groupby(\"id\")[\"spend\"]\n",
    "                               .rolling(3).mean().reset_index(level=0, drop=True))\n",
    "panel[\"rolling_std_6\"]  = (panel.groupby(\"id\")[\"spend\"]\n",
    "                               .rolling(6).std().reset_index(level=0, drop=True))\n",
    "\n",
    "# --- 5.  SEASONALITY -----------------------------------------------\n",
    "panel[\"month_idx\"]  = panel[\"month\"].dt.month\n",
    "panel[\"month_sin\"]  = np.sin(2 * np.pi * panel[\"month_idx\"] / 12)\n",
    "panel[\"month_cos\"]  = np.cos(2 * np.pi * panel[\"month_idx\"] / 12)\n",
    "\n",
    "# --- 5b. HOLIDAY FEATURES -------------------------------------------\n",
    "def is_buen_fin(date): return date.month == 11 and date.day >= 15\n",
    "def is_navidad(date): return date.month == 12 and date.day >= 20\n",
    "def is_mothers_day(date): return date.month == 5 and date.day == 10\n",
    "\n",
    "txn[\"buen_fin\"] = txn[\"fecha\"].apply(is_buen_fin)\n",
    "txn[\"navidad\"] = txn[\"fecha\"].apply(is_navidad)\n",
    "txn[\"dia_madre\"] = txn[\"fecha\"].apply(is_mothers_day)\n",
    "\n",
    "holiday_agg = txn.groupby([\"id\", txn[\"fecha\"].dt.to_period(\"M\")])[[\"buen_fin\", \"navidad\", \"dia_madre\"]].sum().reset_index()\n",
    "holiday_agg.rename(columns={\"fecha\": \"month\"}, inplace=True)\n",
    "panel = panel.merge(holiday_agg, on=[\"id\", \"month\"], how=\"left\").fillna(0)\n",
    "\n",
    "# --- 6.  TARGET -----------------------------------------------------\n",
    "panel[\"spend_next\"] = panel.groupby(\"id\")[\"spend\"].shift(-1)\n",
    "panel = panel.dropna(subset=[\"spend_next\", \"spend_lag1\"])  # keep only full-feature rows\n",
    "\n",
    "# --- DEFINE FEATURE COLS -------------------------------------------\n",
    "feature_cols = [\n",
    "    \"spend\", \"n_tx\", \"max_tx\", \"avg_ticket\",\n",
    "    \"spend_lag1\", \"spend_lag2\", \"spend_lag3\", \"spend_lag4\", \"spend_lag5\", \"spend_lag6\",\n",
    "    \"rolling_mean_3\", \"rolling_std_6\",\n",
    "    \"age\", \"tenure_months\", \"id_estado\", \"tipo_persona\", \"genero\", \"actividad_empresarial\",\n",
    "    \"month_sin\", \"month_cos\",\n",
    "    \"buen_fin\", \"navidad\", \"dia_madre\"\n",
    "]\n",
    "\n",
    "# chronological split (same cut for every client)\n",
    "train_mask = panel[\"month\"] <= panel[\"month\"].max() - 3   # months 1-10\n",
    "val_mask   = panel[\"month\"] == panel[\"month\"].max() - 2   # month 11\n",
    "test_mask  = panel[\"month\"] == panel[\"month\"].max() - 1   # month 12\n",
    "\n",
    "X_train, y_train = panel.loc[train_mask, feature_cols], panel.loc[train_mask, \"spend_next\"]\n",
    "X_val,   y_val   = panel.loc[val_mask,   feature_cols], panel.loc[val_mask,   \"spend_next\"]\n",
    "X_test,  y_test  = panel.loc[test_mask,  feature_cols], panel.loc[test_mask,  \"spend_next\"]\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping # ADDED for callbacks\n",
    "\n",
    "cat_features = [\"id_estado\", \"tipo_persona\", \"genero\", \"actividad_empresarial\"]\n",
    "for col in cat_features: # Ensure categorical features are category type\n",
    "    panel[col] = panel[col].astype(\"category\")\n",
    "\n",
    "model = lgb.LGBMRegressor(\n",
    "    objective     = \"regression_l1\",\n",
    "    n_estimators  = 800,\n",
    "    learning_rate = 0.05,\n",
    "    num_leaves    = 64,\n",
    "    subsample     = 0.8,\n",
    "    colsample_bytree = 0.8,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=\"l1\",\n",
    "    categorical_feature=cat_features,\n",
    "    callbacks=[early_stopping(stopping_rounds=50)] # Corrected early stopping\n",
    ")\n",
    "\n",
    "def predict_client_next_month(model, client_id, monthly_panel):\n",
    "    features = monthly_panel.loc[\n",
    "        monthly_panel[\"id\"] == client_id\n",
    "    ].sort_values(\"month\").tail(1)  # most recent month\n",
    "    return float(model.predict(features[feature_cols]))\n",
    "\n",
    "segment_medians = panel.groupby(\"id_estado\")[\"spend_next\"].median().to_dict() # ADDED for safe_predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0710a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI # ADDED\n",
    "app = FastAPI() # ADDED\n",
    "\n",
    "@app.get(\"/forecast/{client_id}\")\n",
    "def forecast(client_id: int):\n",
    "    y_hat = predict_client_next_month(model, client_id, panel)\n",
    "    return {\"client_id\": client_id, \"next_month_spend\": y_hat}\n",
    "\n",
    "def safe_predict(client_id):\n",
    "    hist_len = panel.loc[panel[\"id\"] == client_id, \"spend\"].count()\n",
    "    if hist_len < 4:\n",
    "        segment = panel.loc[panel[\"id\"] == client_id, \"id_estado\"].iat[0]\n",
    "        return segment_medians.get(segment, 0)   # pre-computed\n",
    "    return predict_client_next_month(model, client_id, panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d3c53",
   "metadata": {},
   "source": [
    "7 Next steps you should schedule\n",
    "Optuna sweep (40 trials) to fine-tune num_leaves, min_child_samples, etc.\n",
    "\n",
    "Holiday calendar dummy for Buen Fin, Navidad, Día de la Madre; they distort Mexican retail spend.\n",
    "\n",
    "SHAP monitoring—log global and per-segment MAE monthly; trigger alert if drift.\n",
    "\n",
    "Stateless scoring image—Dockerfile FROM python:3.12-slim, copy artefact, expose /forecast."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
